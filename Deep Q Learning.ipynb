{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modern Neural Network, adapted from https://github.com/Newmu/Theano-Tutorials\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import random\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype = theano.config.floatX)\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "    \n",
    "    #Simplified RMSprop\n",
    "    def RMSprop(self, cost, weights, lr = 0.001, rho = 0.9, eps = 1e-6):\n",
    "        grads = T.grad(cost = cost, wrt = weights)\n",
    "        updates = []\n",
    "        \n",
    "        for w, g in zip(weights, grads):\n",
    "            acc = theano.shared(w.get_value()*0.)\n",
    "            acc_new = rho * acc + (1 - rho) * g**2\n",
    "            grad_scale = T.sqrt(acc_new + eps)\n",
    "            g = g/grad_scale\n",
    "            updates.append((acc, acc_new))\n",
    "            updates.append((w, w - lr*g))\n",
    "        \n",
    "        return updates    \n",
    "    \n",
    "    #Random dropout for noise\n",
    "    def dropout(self, X, P = 0.):\n",
    "        if P > 0:\n",
    "            X *= srng.binomial(X.shape, p = (1-P), dtype = theano.config.floatX)\n",
    "            X /= (1-P)\n",
    "        \n",
    "        return X\n",
    "        \n",
    "    #Two hidden layer model\n",
    "    def model(self, X, w_h1, w_h2, w_h3, w_out, P_drop_i, P_drop_h):\n",
    "        X = self.dropout(X, P_drop_i)\n",
    "        h1 = rectify(T.dot(X, w_h1))\n",
    "        \n",
    "        h1 = self.dropout(h1, P_drop_h)\n",
    "        h2 = rectify(T.dot(h1, w_h2))\n",
    "        \n",
    "        h2 = self.dropout(h2, P_drop_h)\n",
    "        h3 = rectify(T.dot(h2, w_h3))\n",
    "        \n",
    "        h3 = self.dropout(h3, P_drop_h)\n",
    "        py_x = T.dot(h3, w_out)\n",
    "        \n",
    "        return h1, h2, h3, py_x\n",
    "    \n",
    "    def __init__(self, n_in, n_h1, n_h2, n_h3, n_out, lr, P_drop_i, P_drop_h):\n",
    "        self.X = T.fmatrix()\n",
    "        self.Y = T.fmatrix()\n",
    "        \n",
    "        #Init weights\n",
    "        self.w_h1 = init_weights((n_in, n_h1))\n",
    "        self.w_h2 = init_weights((n_h1, n_h2))\n",
    "        self.w_h3 = init_weights((n_h2, n_h3))\n",
    "        self.w_out = init_weights((n_h3, n_out))\n",
    "        print \"Initializing Weights\"\n",
    "        #Init model\n",
    "        self.noise_h1, self.noise_h2, self.noise_h3, self.noise_py_x = \\\n",
    "        self.model(self.X, self.w_h1, self.w_h2, self.w_h3, self.w_out, P_drop_i, P_drop_h)\n",
    "        self.h1, self.h2, self.h3, self.py_x = \\\n",
    "        self.model(self.X, self.w_h1, self.w_h2, self.w_h3, self.w_out, 0., 0.)\n",
    "        self.y_x_class = T.argmax(self.py_x, axis=1)\n",
    "        self.y_x_value = T.max(self.py_x, axis=1)\n",
    "        print \"Initializing Model\"\n",
    "        \n",
    "        #Cost and Updates\n",
    "        self.cost = T.mean(T.nnet.categorical_crossentropy(self.noise_py_x, self.Y))\n",
    "        self.weights = [self.w_h1, self.w_h2, self.w_h3, self.w_out]\n",
    "        self.updates = self.RMSprop(self.cost, self.weights, lr=lr)\n",
    "        print \"Cost and Updates Done!\"\n",
    "        \n",
    "        #Compile to Theano functions\n",
    "        self.train = theano.function(inputs = [self.X, self.Y],\n",
    "                                     outputs = self.cost,\n",
    "                                     updates = self.updates,\n",
    "                                     allow_input_downcast = True)\n",
    "        self.predict = theano.function(inputs = [self.X],\n",
    "                                             outputs = [self.y_x_class, \n",
    "                                                        self.y_x_value,\n",
    "                                                        self.py_x], \n",
    "                                             allow_input_downcast = True)\n",
    "        print \"Traing and Predicting Function Complete!\"\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1010! Game with modifications\n",
    "import random\n",
    "\n",
    "class Game(object):\n",
    "    def __init__(self):\n",
    "        self.state = [[0 for i in range(10)] for j in range(10)]\n",
    "        self.tiles = [[(0,0), (0,1), (0,2), (1,0), (1,1), (1,2), (2,0), (2,1), (2,2)],\n",
    "                      [(0,0), (1,0), (2,0), (2,1), (2,2)],\n",
    "                      [(0,0), (0,1), (0,2)],\n",
    "                      [(0,0), (1,0), (2,0)],\n",
    "                      [(0,0)],\n",
    "                      [(0,0), (0,1)],\n",
    "                      [(0,0), (1,0)],\n",
    "                      [(0,0), (0,1), (1,0), (1,1)],\n",
    "                      [(0,0), (0,1), (0,2), (1,0), (2,0)],\n",
    "                      [(0,0), (0,1), (0,2), (1,2), (2,2)],\n",
    "                      [(0,2), (1,2), (2,0), (2,1), (2,2)],\n",
    "                      [(0,0), (0,1), (0,2), (0,3)],\n",
    "                      [(0,0), (1,0), (2,0), (3,0)],\n",
    "                      [(0,0), (1,0), (2,0), (3,0), (4,0)],\n",
    "                      [(0,1), (1,0), (1,1)],\n",
    "                      [(0,0), (0,1), (1,0)],\n",
    "                      [(0,0), (0,1), (1,1)],\n",
    "                      [(0,0), (1,0), (1,1)],\n",
    "                      [(0,0), (0,1), (0,2), (0,3), (0,4)]]\n",
    "        self.combo_score = [0 for i in range(10)]\n",
    "        self.score = 0\n",
    "        self.terminal = False\n",
    "        self.valid_tile = [random.randint(0, 18) for i in range(3)]\n",
    "        #Real Scores XD\n",
    "        for i in xrange(1, 10):\n",
    "            self.combo_score[i] = self.combo_score[i-1] + 10*i\n",
    "        \n",
    "    #Validate action\n",
    "    def valid_action(self, action, tile):\n",
    "        row, col = action\n",
    "        valid_flag = True\n",
    "        \n",
    "        if(not tile in self.valid_tile):\n",
    "            valid_flag = False\n",
    "            return valid_flag\n",
    "        \n",
    "        for dr, dc in self.tiles[tile]:\n",
    "            if(row + dr > 9 or col + dc > 9 or self.state[row + dr][col + dc] == 1):\n",
    "                valid_flag = False\n",
    "                break\n",
    "\n",
    "        return valid_flag\n",
    "            \n",
    "    #Clear valid lines\n",
    "    def update_state(self, clear_row, clear_col):\n",
    "        for row in clear_row:\n",
    "            for col in range(10):\n",
    "                self.state[row][col] = 0\n",
    "        \n",
    "        for col in clear_col:\n",
    "            for row in range(10):\n",
    "                self.state[row][col] = 0\n",
    "    \n",
    "    #Calculate and clear lines\n",
    "    def check_score(self):\n",
    "        \n",
    "        clear_lines = 0\n",
    "        clear_row = []\n",
    "        clear_col = []\n",
    "        \n",
    "        for row in xrange(10):\n",
    "            row_flag = True\n",
    "            for col in xrange(10):\n",
    "                if(self.state[row][col] == 0):\n",
    "                    row_flag = False\n",
    "                    break\n",
    "                \n",
    "            if(row_flag == True):\n",
    "                clear_row.append(row)\n",
    "                clear_lines += 1\n",
    "        \n",
    "        for col in xrange(10):\n",
    "            col_flag = True\n",
    "            for row in xrange(10):\n",
    "                if(self.state[row][col] == 0):\n",
    "                    col_flag = False\n",
    "                    break\n",
    "            \n",
    "            if(col_flag == True):\n",
    "                clear_col.append(col)\n",
    "                clear_lines += 1\n",
    "        \n",
    "        self.update_state(clear_row, clear_col)\n",
    "        \n",
    "        return self.combo_score[clear_lines]\n",
    "        \n",
    "    #Add the tile on specified coordinate, returns score\n",
    "    def add_tile(self, action, tile):\n",
    "        row, col = action\n",
    "        if(self.valid_action(action, tile) == True):\n",
    "            for dr, dc in self.tiles[tile]:\n",
    "                self.state[row + dr][col + dc] = 1;\n",
    "            \n",
    "            return len(self.tiles[tile]) + self.check_score()\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "       \n",
    "    def start_game(self):\n",
    "        #print \"Game Starts!\"\n",
    "        self.__init__()\n",
    "        return self.score, self.state, self.valid_tile, self.terminal\n",
    "    \n",
    "    def end_game(self):\n",
    "        end_flag = True\n",
    "        for tile in self.valid_tile:\n",
    "            for row in xrange(10):\n",
    "                for col in xrange(10):\n",
    "                    if(self.valid_action((row, col), tile)):\n",
    "                        end_flag = False\n",
    "                    \n",
    "        return end_flag\n",
    "    \n",
    "    def do_action(self, action, tile):\n",
    "        \n",
    "        if(not tile in self.valid_tile):\n",
    "            #print \"Invalid Tile\"\n",
    "            pass\n",
    "        else:\n",
    "            temp_score = self.add_tile(action, tile)\n",
    "            if(temp_score == False):\n",
    "                #print \"Invalid Action\"\n",
    "                pass\n",
    "            else:\n",
    "                self.score += temp_score\n",
    "                self.valid_tile.remove(tile)\n",
    "        \n",
    "        if(self.valid_tile == []):\n",
    "            self.valid_tile = [random.randint(0, 18) for i in range(3)]\n",
    "        \n",
    "        if(self.end_game() == True):\n",
    "            self.terminal = True\n",
    "            #print \"Game Over\"\n",
    "        \n",
    "        return self.score, self.state, self.valid_tile, self.terminal\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Deep Q Learning\n",
    "\n",
    "def state_to_input(state, tiles):\n",
    "    state = np.array(state)\n",
    "    state_input = state.flatten()\n",
    "    tile_input = np.zeros((19,))\n",
    "    if type(tiles) == list:\n",
    "        for i in tiles:\n",
    "            tile_input[i] += 1\n",
    "    \n",
    "    state_input = np.append(state_input, tile_input)\n",
    "    return state_input\n",
    "\n",
    "def output_to_action(output, tiles):\n",
    "    tile_idx = output/100\n",
    "    output = output%100\n",
    "    act = (output/10, output%10)\n",
    "    tile = 0\n",
    "    \n",
    "    if type(tiles) == list:\n",
    "        if(tile_idx > len(tiles)-1):\n",
    "            tile = 19\n",
    "        else:\n",
    "            tile = tiles[tile_idx]\n",
    "    \n",
    "    return act, tile\n",
    "\n",
    "class DeepQ(object):\n",
    "    \n",
    "    def __init__(self, n_in, n_h1, n_h2, n_h3, n_out, lr, P_drop_i, P_drop_h):\n",
    "        self.game = Game()\n",
    "        self.nn = MLP(n_in, n_h1, n_h2, n_h3, n_out, lr, P_drop_i, P_drop_h)\n",
    "        self.exp = []\n",
    "\n",
    "    def learn(self, n_epoch, exp_len, time_len, eps, gamma):\n",
    "        train_score = []\n",
    "        for e in xrange(n_epoch):\n",
    "            \n",
    "            #Start epoch\n",
    "            score, state, valid_tile, terminal = self.game.start_game()\n",
    "            \n",
    "            for t in xrange(time_len):\n",
    "                \n",
    "                #Epsilon greedy\n",
    "                policy_output = 0\n",
    "                a_t = (0,0)\n",
    "                tile_t = 0\n",
    "                if(random.random() < eps):\n",
    "                    for policy_t in xrange(300):\n",
    "                        a_t, tile_t = output_to_action(policy_t, valid_tile)\n",
    "                        if(self.game.valid_action(a_t, tile_t)):\n",
    "                            policy_output = policy_t\n",
    "                            break\n",
    "                else:\n",
    "                    pred = self.nn.predict([state_to_input(state, valid_tile)])\n",
    "                    policy_outputs = sorted(range(len(pred[2][0])), key = lambda k:-pred[2][0][k])\n",
    "                    #Choose Valid Policy with Max Q Value\n",
    "                    for policy_t in policy_outputs:\n",
    "                        a_t, tile_t = output_to_action(policy_t, valid_tile)\n",
    "                        if(self.game.valid_action(a_t, tile_t)):\n",
    "                            policy_output = policy_t\n",
    "                            break\n",
    "                    \n",
    "                score_t, state_t, valid_tile_t, terminal = self.game.do_action(a_t, tile_t)\n",
    "                reward = (score_t - score) - 0.5\n",
    "\n",
    "                #Store Experience\n",
    "                self.exp.append({'state':state, \n",
    "                                 'valid_tile':valid_tile, \n",
    "                                 'policy_output':policy_output,\n",
    "                                 'reward':reward,\n",
    "                                 'state_t':state_t,\n",
    "                                 'valid_tile_t':valid_tile_t,\n",
    "                                 'terminal':terminal})\n",
    "                score = score_t\n",
    "                state = state_t\n",
    "                valid_tile = valid_tile_t\n",
    "                \n",
    "                #Experience Replay\n",
    "                if(len(self.exp) > exp_len):\n",
    "                    trX = []\n",
    "                    trY = []\n",
    "                    i = random.randint(0, exp_len-1)\n",
    "                    if(self.exp[i]['terminal'] == True):\n",
    "                        Q = self.exp[i]['reward']\n",
    "                    else:\n",
    "                        pred = self.nn.predict([state_to_input(self.exp[i]['state_t'],\n",
    "                                                               self.exp[i]['valid_tile_t'])])\n",
    "                        Q = self.exp[i]['reward'] + gamma * pred[1][0]\n",
    "                        \n",
    "                    y = pred[2][0]\n",
    "                    y[self.exp[i]['policy_output']] = Q\n",
    "                    trX.append(state_to_input(self.exp[i]['state'], self.exp[i]['valid_tile']))\n",
    "                    trY.append(y)\n",
    "                    del self.exp[i]\n",
    "                    trX = np.asarray(trX)\n",
    "                    trY = np.asarray(trY)\n",
    "                    self.nn.train(trX, trY)\n",
    "\n",
    "                if(terminal == True):\n",
    "                    break\n",
    "            train_score.append(score)\n",
    "            #print \"Learning Epoch: %d, Score: %d\" % (e, score)\n",
    "        \n",
    "        return train_score\n",
    "    \n",
    "    def play(self, epoch):\n",
    "        final_score = []\n",
    "        for e in xrange(epoch):\n",
    "            score, state, valid_tile, terminal = self.game.start_game()\n",
    "            while(True):\n",
    "                a_t = (0, 0)\n",
    "                tile_t = 0\n",
    "                pred = self.nn.predict([state_to_input(state, valid_tile)])\n",
    "                policy_outputs = sorted(range(len(pred[2][0])), key = lambda k:-pred[2][0][k])\n",
    "                \n",
    "                for policy_t in policy_outputs:\n",
    "                    a_t, tile_t = output_to_action(policy_t, valid_tile)\n",
    "                    if(self.game.valid_action(a_t, tile_t)):\n",
    "                        break\n",
    "                    \n",
    "                \n",
    "                score, state, valid_tile, terminal = self.game.do_action(a_t, tile_t)\n",
    "                \n",
    "                if(terminal == True):\n",
    "                    break\n",
    "                    \n",
    "            final_score.append(score)\n",
    "            print \"Playing epoch: %d, Score: %d\" % (e, score)\n",
    "            \n",
    "        return final_score\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Weights\n",
      "Initializing Model\n",
      "Cost and Updates Done!\n",
      "Traing and Predicting Function Complete!"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "Learner = DeepQ(119, 128, 128, 128, 300, 0.001, 0, 0)\n",
    "graph_y = Learner.learn(200000, 2000, 4000, 0.1, 0.99)\n",
    "graph_x = [i for i in range(200000)] \n",
    "print np.average(graph_y)\n",
    "plt.plot(graph_x, graph_y, 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_y = Learner.play(100)\n",
    "graph_x = [i for i in range(100)] \n",
    "print np.average(graph_y)\n",
    "plt.plot(graph_x, graph_y, 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Learner.nn.w_h1.get_value()\n",
    "print Learner.nn.w_h2.get_value()\n",
    "print Learner.nn.w_out.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
